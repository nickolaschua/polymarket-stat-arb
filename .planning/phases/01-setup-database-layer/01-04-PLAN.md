---
phase: 01-setup-database-layer
plan: 04
type: tdd
---

<objective>
Build query functions for market metadata and resolution tracking — both use UPSERT (INSERT ON CONFLICT) patterns for idempotent data ingestion.

Purpose: Markets and resolutions are updated by collectors via upserts. TDD ensures upsert semantics are correct: new rows insert, existing rows update, conflicts resolve properly.
Output: src/db/queries/markets.py, src/db/queries/resolutions.py, passing integration tests.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-setup-database-layer/01-RESEARCH.md
@.planning/phases/01-setup-database-layer/01-01-SUMMARY.md
@.planning/phases/01-setup-database-layer/01-02-SUMMARY.md
@.planning/phases/01-setup-database-layer/01-03-SUMMARY.md

@src/db/pool.py
@src/db/models.py
@src/db/migrations/002_markets.sql
@src/db/migrations/006_resolutions.sql
@tests/conftest.py

**Query function pattern (from research):**
- Thin functions: take pool + data, return Pydantic models
- Use pool.execute() for writes, pool.fetch()/pool.fetchrow() for reads
- Use `$1::text[]` for array parameters (not IN clause)
- Return Pydantic models via record_to_model() helper

**Market upsert pattern:**
- INSERT INTO markets (...) VALUES ($1, $2, ...) ON CONFLICT (condition_id) DO UPDATE SET question=$2, ..., updated_at=NOW()
- Collector calls this every 5 minutes for all active markets

**Resolution upsert pattern:**
- INSERT INTO resolutions (...) VALUES ($1, $2, ...) ON CONFLICT (condition_id) DO UPDATE SET outcome=$2, ..., resolved_at=$4
- Triggered when resolution detected (final prices, Gamma API status change)
</context>

<feature>
  <name>Market + Resolution Query Functions</name>
  <files>src/db/queries/__init__.py, src/db/queries/markets.py, src/db/queries/resolutions.py, tests/db/test_markets.py, tests/db/test_resolutions.py</files>
  <behavior>
    **Market queries:**
    - upsert_market(pool, market_data) → inserts new market or updates existing
    - upsert_markets(pool, list[market_data]) → batch upsert (uses executemany or loop)
    - get_market(pool, condition_id) → MarketRecord | None
    - get_active_markets(pool) → list[MarketRecord]
    - get_markets_by_ids(pool, condition_ids: list[str]) → list[MarketRecord]

    Test cases (markets):
    1. upsert_market with new data → inserts, get_market returns it
    2. upsert_market with same condition_id but updated question → updates, updated_at changes
    3. upsert_markets with 3 markets → all 3 inserted
    4. get_active_markets → only returns markets where active=True
    5. get_markets_by_ids with list → returns matching, uses ANY($1::text[])

    **Resolution queries:**
    - upsert_resolution(pool, resolution_data) → inserts or updates resolution
    - get_resolution(pool, condition_id) → ResolutionRecord | None
    - get_unresolved_markets(pool) → list of condition_ids with no resolution

    Test cases (resolutions):
    1. upsert_resolution with new data → inserts, get_resolution returns it
    2. upsert_resolution with updated outcome → updates existing
    3. get_unresolved_markets → returns condition_ids in markets table that have no matching resolution
  </behavior>
  <implementation>
    Create src/db/queries/ package with __init__.py.

    **markets.py:**
    - All functions take `pool: asyncpg.Pool` as first argument
    - upsert_market: INSERT ... ON CONFLICT (condition_id) DO UPDATE SET question=EXCLUDED.question, slug=EXCLUDED.slug, market_type=EXCLUDED.market_type, outcomes=EXCLUDED.outcomes, clob_token_ids=EXCLUDED.clob_token_ids, active=EXCLUDED.active, closed=EXCLUDED.closed, end_date_iso=EXCLUDED.end_date_iso, updated_at=NOW()
    - upsert_markets: Loop over list calling upsert_market (simple, not perf-critical at 5-min intervals for ~8K markets). Consider using asyncpg's executemany for better performance if needed.
    - get_market: SELECT * FROM markets WHERE condition_id = $1
    - get_active_markets: SELECT * FROM markets WHERE active = true ORDER BY created_at DESC
    - get_markets_by_ids: SELECT * FROM markets WHERE condition_id = ANY($1::text[])
    - All reads return Pydantic models via record_to_model()

    **resolutions.py:**
    - upsert_resolution: INSERT ... ON CONFLICT (condition_id) DO UPDATE SET outcome=EXCLUDED.outcome, winner_token_id=EXCLUDED.winner_token_id, resolved_at=EXCLUDED.resolved_at, payout_price=EXCLUDED.payout_price, detection_method=EXCLUDED.detection_method
    - get_resolution: SELECT * FROM resolutions WHERE condition_id = $1
    - get_unresolved_markets: SELECT m.condition_id FROM markets m LEFT JOIN resolutions r ON m.condition_id = r.condition_id WHERE r.condition_id IS NULL AND m.closed = true

    **Test fixtures:** Each test file gets a `migrated_pool` fixture that runs all migrations on the test db_pool. Use the clean_db fixture for isolation between tests.

    Do NOT use `pool.copy_records_to_table` for markets/resolutions — these are upserts, not bulk inserts. COPY doesn't support ON CONFLICT.
  </implementation>
</feature>

<verification>
pytest tests/db/test_markets.py tests/db/test_resolutions.py -v
</verification>

<success_criteria>
- Failing tests written and committed (RED)
- Query functions pass all tests (GREEN)
- Refactor if needed (REFACTOR)
- Upserts are idempotent (insert+update work correctly)
- Array parameter queries use ANY($1::text[])
- All functions return Pydantic models
- All 2-3 commits present
</success_criteria>

<output>
After completion, create `.planning/phases/01-setup-database-layer/01-04-SUMMARY.md` with:
- RED: What tests were written, why they failed
- GREEN: What implementation made them pass
- REFACTOR: What cleanup was done (if any)
- Commits: List of commits produced
</output>
