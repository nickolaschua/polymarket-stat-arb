---
phase: 03-websocket-trades
plan: 04
type: execute
---

<objective>
Add connection pooling for >500 tokens, run/stop lifecycle management, and health state tracking to the TradeListener.

Purpose: Production readiness — the listener must handle 8,000+ markets (16,000+ tokens) across multiple WebSocket connections with graceful shutdown and observable health state.
Output: Complete TradeListener with connection pooling, lifecycle management, health tracking, and integration tests.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-websocket-trades/03-RESEARCH.md
@.planning/phases/03-websocket-trades/03-CONTEXT.md

# Prior plan outputs:
@.planning/phases/03-websocket-trades/03-01-SUMMARY.md
@.planning/phases/03-websocket-trades/03-02-SUMMARY.md
@.planning/phases/03-websocket-trades/03-03-SUMMARY.md

# Key source files:
@src/collector/trade_listener.py
@src/db/queries/markets.py
@src/db/models.py
@src/config.py
@tests/collector/test_trade_listener.py
@tests/collector/conftest.py

**Tech stack available:** asyncpg, websockets>=16.0, pydantic
**Established patterns:**
- TradeListener._listen_single(token_ids) from 03-03 for single-connection lifecycle
- get_active_markets(pool) returns MarketRecord list with clob_token_ids
- ws_max_instruments_per_conn=500 in CollectorConfig (from 03-03)
- asyncio.Queue(maxsize=10000) shared across connections
- CONTEXT.md: "Structured observability — logs and queryable health state"

**Constraining decisions:**
- 500 instruments max per WS connection (RESEARCH.md pitfall 3)
- Must chunk token_ids and run one _listen_single per chunk concurrently
- Must re-subscribe after reconnect (RESEARCH.md pitfall 4)
- _listen_single already handles reconnect via websockets async iterator (from 03-03)
- Drain loop is shared (single consumer for all connections' queue)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add connection pooling and run/stop lifecycle</name>
  <files>src/collector/trade_listener.py</files>
  <action>
    Extend TradeListener class with connection pooling and lifecycle management:

    1. Add health state dataclass at module level:
       @dataclass
       class TradeListenerHealth:
           trades_received: int = 0        (total trade events parsed and queued)
           trades_inserted: int = 0        (total trades written to DB)
           batches_inserted: int = 0       (total batch insert_trades calls)
           connections_active: int = 0     (currently connected WS count)
           reconnections: int = 0          (total reconnection events)
           queue_depth: int = 0            (current queue size, updated on access)
           last_trade_ts: datetime | None = None     (timestamp of most recent trade event)
           last_insert_ts: datetime | None = None    (timestamp of most recent batch insert)
           last_reconnect_ts: datetime | None = None (timestamp of most recent reconnect)
           started_at: datetime | None = None

    2. Add health attribute to __init__:
       self.health = TradeListenerHealth()

    3. Update _receive_loop to increment health.trades_received on each successful parse.

    4. Update _drain_loop to increment health.trades_inserted and health.batches_inserted and set health.last_insert_ts after successful insert.

    5. Update _listen_single to:
       - Increment health.connections_active on connect, decrement on disconnect
       - Increment health.reconnections and set health.last_reconnect_ts on reconnect (after ConnectionClosed except block, before continue)

    6. Add _get_active_token_ids(self) -> list[str]:
       - Query get_active_markets(self.pool)
       - Flatten all clob_token_ids from all active markets into a single list
       - Deduplicate (set -> list)
       - Log: "Found N unique tokens from M active markets"

    7. Add async def run(self) -> None:
       - self._running = True
       - self.health.started_at = datetime.now(timezone.utc)
       - token_ids = await self._get_active_token_ids()
       - If no tokens, log warning and return
       - chunk_size = self.config.ws_max_instruments_per_conn
       - chunks = [token_ids[i:i+chunk_size] for i in range(0, len(token_ids), chunk_size)]
       - Log: "Starting N connections for M tokens (chunk_size=K)"
       - Start drain task: drain_task = asyncio.create_task(self._drain_loop())
       - Start one _listen_single task per chunk:
         listener_tasks = [asyncio.create_task(self._listen_single(chunk)) for chunk in chunks]
       - self._tasks = [drain_task] + listener_tasks
       - await asyncio.gather(*self._tasks, return_exceptions=True)
         (blocks until stop() is called or all tasks complete)

    8. Add async def stop(self) -> None:
       - self._running = False
       - Cancel all tasks in self._tasks
       - await asyncio.gather(*self._tasks, return_exceptions=True)
       - Drain any remaining items in queue:
         remaining = []
         while not self._queue.empty():
           try: remaining.append(self._queue.get_nowait())
           except asyncio.QueueEmpty: break
         if remaining:
           try: await insert_trades(self.pool, remaining)
           except Exception: logger.error("Failed to flush remaining trades", exc_info=True)
       - Log: "TradeListener stopped. Health: {self.health}"

    9. Add def get_health(self) -> TradeListenerHealth:
       - Update self.health.queue_depth = self._queue.qsize()
       - Return copy of self.health

    AVOID:
    - Refreshing token list during run() — token list is fetched once at startup. Dynamic refresh adds complexity for Phase 4 daemon supervisor to handle.
    - Creating a new queue per connection — all connections share one queue, one drain loop.
    - Catching CancelledError in run() — let it propagate for clean shutdown.
  </action>
  <verify>python -c "from src.collector.trade_listener import TradeListener, TradeListenerHealth; print('import OK')"</verify>
  <done>TradeListener has run(), stop(), get_health(), _get_active_token_ids(), and TradeListenerHealth dataclass</done>
</task>

<task type="auto">
  <name>Task 2: Write integration and health state tests</name>
  <files>tests/collector/test_trade_listener.py</files>
  <action>
    Extend tests/collector/test_trade_listener.py with connection pooling and lifecycle tests.
    Use unittest.mock.AsyncMock and unittest.mock.patch for websockets.

    Connection pooling tests:

    1. test_get_active_token_ids_flattens_and_deduplicates:
       - Use migrated_pool, insert 3 markets with overlapping clob_token_ids
       - Call _get_active_token_ids()
       - Assert returns deduplicated flat list of all token IDs

    2. test_get_active_token_ids_empty_when_no_markets:
       - Use migrated_pool with no markets
       - Returns empty list

    3. test_run_chunks_tokens_into_connections:
       - Mock _listen_single and _drain_loop as AsyncMock
       - Set ws_max_instruments_per_conn=2
       - Mock _get_active_token_ids to return ["t1","t2","t3","t4","t5"]
       - Call run() (it will await gather, which completes immediately with mocks)
       - Assert _listen_single called 3 times: ["t1","t2"], ["t3","t4"], ["t5"]
       - Assert _drain_loop called once

    4. test_run_no_tokens_returns_early:
       - Mock _get_active_token_ids to return []
       - Call run() — should return without starting tasks

    Lifecycle tests:

    5. test_stop_cancels_tasks:
       - Start run() as background task
       - Mock _listen_single to sleep forever
       - Mock _drain_loop to sleep forever
       - Call stop()
       - Assert all tasks cancelled

    6. test_stop_flushes_remaining_queue:
       - Put trade tuples in queue
       - Mock insert_trades
       - Call stop()
       - Assert insert_trades called with remaining items

    Health state tests:

    7. test_health_initial_state:
       - Create TradeListener
       - Assert health has all zeros/Nones

    8. test_health_updates_on_trades:
       - Mock WS to yield one trade event then cancel
       - Run _listen_single briefly
       - Assert health.trades_received incremented
       - Run _drain_loop briefly with pre-filled queue, mock insert_trades
       - Assert health.trades_inserted incremented, health.last_insert_ts set

    9. test_get_health_returns_current_queue_depth:
       - Put 5 items in queue
       - Call get_health()
       - Assert queue_depth == 5

    Use migrated_pool fixture for tests that need DB (test_get_active_token_ids, test_stop_flushes).
    Use pure mocks for lifecycle and health state tests.
  </action>
  <verify>pytest tests/collector/test_trade_listener.py -v -- all tests pass (both 03-03 tests and new tests)</verify>
  <done>9 new tests covering token chunking, lifecycle management, and health state. All tests pass (03-03 + 03-04).</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] pytest tests/collector/test_trade_listener.py -v -- all tests pass
- [ ] pytest tests/collector/test_resolution_tracker.py -v -- all tests pass
- [ ] pytest tests/collector/ -v -- all collector tests pass
- [ ] pytest tests/ -v -- full test suite passes
- [ ] No import errors or warnings
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- TradeListener handles >500 tokens via connection pooling (chunks of 500)
- run() starts concurrent connections + drain task
- stop() gracefully shuts down and flushes remaining trades
- TradeListenerHealth provides queryable health state
- Phase 3 complete: trade listener + resolution tracker fully implemented and tested
- Full test suite passes (Phase 1 DB + Phase 2 collector + Phase 3 tests)
</success_criteria>

<output>
After completion, create `.planning/phases/03-websocket-trades/03-04-SUMMARY.md`:

# Phase 03 Plan 04: Connection Pooling + Integration Summary

**[Substantive one-liner]**

## Accomplishments
## Files Created/Modified
## Decisions Made
## Issues Encountered

## Phase 3 Completion

Phase 3: WebSocket Trades + Resolution Tracker is **COMPLETE**.

Components delivered:
- infer_winner() with TDD-proven correctness (03-01)
- ResolutionTracker collector with Gamma API polling (03-02)
- TradeListener with event parsing, single-connection logic, queue architecture (03-03)
- Connection pooling, lifecycle management, health state tracking (03-04)

## Next Phase Readiness

Ready for Phase 4: Daemon Supervisor + CLI
- All collectors implemented: metadata, prices, orderbooks, trades, resolutions
- All collectors follow same pattern: collect_once() -> int, never raises
- TradeListener has run()/stop() lifecycle for daemon integration
- Health state queryable for monitoring
</output>
